#!/usr/bin/env python3
"""
è¿è¡Œå®Œæ•´å®éªŒæµç¨‹çš„è„šæœ¬

æ‰§è¡Œç®—æ³•åŸºå‡†æµ‹è¯•ï¼Œç”Ÿæˆæ€§èƒ½æŒ‡æ ‡å’Œå¯è§†åŒ–å›¾è¡¨ã€‚
"""

import argparse
import logging
import sys
from pathlib import Path

# srcå¸ƒå±€è·¯å¾„ä¿®æ­£
sys.path.insert(0, str(Path(__file__).resolve().parent.parent / "src"))

# å¯¼å…¥é¡¹ç›®æ¨¡å—
from second_shortest_path.algorithms import StateExtendedSPFA, TwoDistanceDijkstra
from second_shortest_path.data import GraphGenerator
from second_shortest_path.evaluation import PerformanceMetrics, Visualizer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def run_experiments(
    graph_sizes: list[int],
    density: float,
    output_dir: str
) -> None:
    """è¿è¡Œå®Œæ•´å®éªŒ
    
    Args:
        graph_sizes: æµ‹è¯•çš„å›¾è§„æ¨¡åˆ—è¡¨
        density: å›¾çš„å¯†åº¦
        output_dir: ç»“æœè¾“å‡ºç›®å½•
    """
    output_path = Path(output_dir)
    metrics_dir = output_path / "metrics"
    viz_dir = output_path / "visualizations"
    
    metrics_dir.mkdir(parents=True, exist_ok=True)
    viz_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info("=" * 60)
    logger.info("å¼€å§‹è¿è¡Œå®éªŒ")
    logger.info("=" * 60)
    
    # 1. ç”Ÿæˆæµ‹è¯•æ•°æ®
    logger.info(f"ğŸ“Š ç”Ÿæˆæµ‹è¯•æ•°æ®: è§„æ¨¡={graph_sizes}, å¯†åº¦={density}")
    test_suite = GraphGenerator.generate_test_suite(graph_sizes, density)
    
    # æ·»åŠ ç‰¹æ®Šæµ‹è¯•ç”¨ä¾‹
    special_cases = GraphGenerator.generate_special_cases()
    test_suite.extend(special_cases)
    
    logger.info(f"âœ… ç”Ÿæˆ {len(test_suite)} ä¸ªæµ‹è¯•å›¾")
    
    # 2. åˆå§‹åŒ–ç®—æ³•ï¼ˆæ³¨æ„ï¼šéœ€è¦ä¸ºæ¯ä¸ªæµ‹è¯•å•ç‹¬åˆ›å»ºå®ä¾‹ï¼‰
    logger.info("ğŸ”§ åˆå§‹åŒ–ç®—æ³•")
    algorithm_classes = [TwoDistanceDijkstra, StateExtendedSPFA]
    
    # 3. è¿è¡ŒåŸºå‡†æµ‹è¯•
    logger.info("ğŸš€ å¼€å§‹åŸºå‡†æµ‹è¯•")
    metrics = PerformanceMetrics()
    
    # ä¸ºæ¯ä¸ªæµ‹è¯•ç”¨ä¾‹åˆ›å»ºæ–°çš„ç®—æ³•å®ä¾‹
    results_list = []
    for graph_data in test_suite:
        graph = graph_data['graph']
        source = graph_data.get('source', 0)
        target = graph_data.get('target', graph_data['n'] - 1)
        
        for AlgoClass in algorithm_classes:
            algo = AlgoClass(graph)
            result = metrics.run_single_test(algo, graph, source, target)
            result['test_name'] = graph_data.get('test_name', 'unknown')
            result['graph_type'] = graph_data.get('graph_type', 'random')
            results_list.append(result)
    
    # è½¬æ¢ä¸ºDataFrame
    import pandas as pd
    results_df = pd.DataFrame(results_list)
    
    logger.info("âœ… åŸºå‡†æµ‹è¯•å®Œæˆ")
    
    # 4. è®¡ç®—ç»Ÿè®¡æ•°æ®
    logger.info("ğŸ“ˆ è®¡ç®—ç»Ÿè®¡æ•°æ®")
    stats = metrics.calculate_statistics(results_df)
    
    for algo, algo_stats in stats.items():
        logger.info(f"\n{algo}:")
        logger.info(f"  å¹³å‡æ—¶é—´: {algo_stats['time_mean']:.6f}s")
        logger.info(f"  ä¸­ä½æ•°: {algo_stats['time_median']:.6f}s")
        logger.info(f"  P95: {algo_stats['time_p95']:.6f}s")
    
    # 5. å¯¼å‡ºç»“æœ
    logger.info("ğŸ’¾ å¯¼å‡ºç»“æœæ•°æ®")
    metrics.export_results(metrics_dir / "benchmark_results.csv")
    
    # 6. ç”Ÿæˆå¯è§†åŒ–
    logger.info("ğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
    
    Visualizer.plot_runtime_comparison(
        results_df,
        viz_dir / "runtime_comparison.png"
    )
    logger.info("  âœ… è¿è¡Œæ—¶é—´å¯¹æ¯”å›¾")
    
    Visualizer.plot_scalability(
        results_df,
        viz_dir / "scalability.png"
    )
    logger.info("  âœ… å¯æ‰©å±•æ€§åˆ†æå›¾")
    
    Visualizer.plot_complexity_verification(
        results_df,
        viz_dir / "complexity_verification.png"
    )
    logger.info("  âœ… å¤æ‚åº¦éªŒè¯å›¾")
    
    Visualizer.plot_operations_comparison(
        results_df,
        viz_dir / "operations_comparison.png"
    )
    logger.info("  âœ… æ“ä½œæ¬¡æ•°å¯¹æ¯”å›¾")
    
    Visualizer.plot_percentile_comparison(
        results_df,
        viz_dir / "percentile_comparison.png"
    )
    logger.info("  âœ… ç™¾åˆ†ä½æ•°å¯¹æ¯”å›¾")
    
    Visualizer.plot_heatmap(
        results_df,
        viz_dir / "performance_heatmap.png"
    )
    logger.info("  âœ… æ€§èƒ½çƒ­åŠ›å›¾")
    
    logger.info("=" * 60)
    logger.info("âœ… å®éªŒå®Œæˆï¼")
    logger.info(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_path}")
    logger.info("=" * 60)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='è¿è¡Œç¬¬äºŒçŸ­è·¯å¾„ç®—æ³•å¯¹æ¯”å®éªŒ'
    )
    parser.add_argument(
        '--sizes',
        type=int,
        nargs='+',
        default=[10, 50, 100, 500],
        help='æµ‹è¯•çš„å›¾è§„æ¨¡åˆ—è¡¨ï¼ˆé»˜è®¤: 10 50 100 500ï¼‰'
    )
    parser.add_argument(
        '--density',
        type=float,
        default=0.3,
        help='å›¾çš„å¯†åº¦ï¼ˆé»˜è®¤: 0.3ï¼‰'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='results',
        help='ç»“æœè¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: resultsï¼‰'
    )
    parser.add_argument(
        '--all',
        action='store_true',
        help='è¿è¡Œæ‰€æœ‰é¢„è®¾å®éªŒ'
    )
    
    args = parser.parse_args()
    
    if args.all:
        # è¿è¡Œå®Œæ•´çš„å®éªŒå¥—ä»¶
        graph_sizes = [10, 50, 100, 500, 1000]
    else:
        graph_sizes = args.sizes
    
    try:
        run_experiments(graph_sizes, arg s.density, args.output)
    except Exception as e:
        logger.error(f"âŒ å®éªŒè¿è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()

