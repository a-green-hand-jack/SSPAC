#!/usr/bin/env python3
"""
åœ¨LeetCodeæ•°æ®ä¸Šè¿è¡Œç®—æ³•å®éªŒ

éªŒè¯ç®—æ³•çš„æ­£ç¡®æ€§ï¼Œæµ‹è¯•æ€§èƒ½ï¼Œå¹¶ç”Ÿæˆè¯¦ç»†çš„å®éªŒæŠ¥å‘Šå’Œå¯è§†åŒ–ã€‚
"""

import argparse
import json
import logging
import sys
import time
from pathlib import Path

import pandas as pd

# srcå¸ƒå±€è·¯å¾„ä¿®æ­£
sys.path.insert(0, str(Path(__file__).resolve().parent.parent / "src"))

from second_shortest_path.algorithms import StateExtendedSPFA, TwoDistanceDijkstra
from second_shortest_path.evaluation import Visualizer

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def convert_leetcode_case_to_graph(test_case: dict) -> tuple:
    """å°†LeetCodeæµ‹è¯•ç”¨ä¾‹è½¬æ¢ä¸ºå›¾è¡¨ç¤º
    
    Args:
        test_case: LeetCodeæµ‹è¯•ç”¨ä¾‹
    
    Returns:
        (graph, source, target) ä¸‰å…ƒç»„
    """
    n = test_case['n']
    edges = test_case['edges']
    source = test_case['source']
    target = test_case['target']
    
    # æ„å»ºé‚»æ¥è¡¨ï¼ˆæ— å‘å›¾ï¼Œè¾¹æƒé‡ä¸º1ï¼‰
    graph = {i: [] for i in range(n + 1)}  # LeetCodeä½¿ç”¨1-indexed
    
    for u, v in edges:
        graph[u].append((v, 1))
        graph[v].append((u, 1))
    
    return graph, source, target


def run_leetcode_experiments(
    data_file: str,
    output_dir: str = 'results/leetcode_experiments'
) -> None:
    """åœ¨LeetCodeæ•°æ®ä¸Šè¿è¡Œå®Œæ•´å®éªŒ
    
    Args:
        data_file: LeetCodeæ•°æ®æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
    """
    output_path = Path(output_dir)
    metrics_dir = output_path / "metrics"
    viz_dir = output_path / "visualizations"
    
    metrics_dir.mkdir(parents=True, exist_ok=True)
    viz_dir.mkdir(parents=True, exist_ok=True)
    
    logger.info("=" * 70)
    logger.info("LeetCode ç®—æ³•æ€§èƒ½å®éªŒ")
    logger.info("=" * 70)
    
    # åŠ è½½æ•°æ®
    logger.info(f"ğŸ“¥ åŠ è½½æ•°æ®: {data_file}")
    with open(data_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    test_cases = data['test_cases']
    total_cases = len(test_cases)
    
    logger.info(f"âœ… åŠ è½½äº† {total_cases} ä¸ªæµ‹è¯•ç”¨ä¾‹\n")
    
    # åˆå§‹åŒ–ç»Ÿè®¡
    results = []
    official_cases = []  # æœ‰é¢„æœŸç»“æœçš„ç”¨ä¾‹
    generated_cases = []  # æ— é¢„æœŸç»“æœçš„ç”¨ä¾‹
    
    # è¿è¡Œå®éªŒ
    logger.info("ğŸš€ å¼€å§‹è¿è¡Œå®éªŒ...\n")
    
    for idx, test_case in enumerate(test_cases, 1):
        case_id = test_case.get('id', idx)
        name = test_case.get('name', f'Test {case_id}')
        n = test_case['n']
        edges = test_case['edges']
        expected_shortest = test_case.get('expected_shortest')
        expected_second = test_case.get('expected_second_shortest')
        
        logger.info(f"[{idx}/{total_cases}] {name} (n={n}, m={len(edges)})")
        
        # è½¬æ¢å›¾
        graph, source, target = convert_leetcode_case_to_graph(test_case)
        
        # è®°å½•ç”¨ä¾‹ç±»å‹
        has_expected = expected_shortest is not None and expected_second is not None
        
        # æµ‹è¯• Two-Distance Dijkstra
        dijkstra = TwoDistanceDijkstra(graph)
        start_time = time.perf_counter()
        d_shortest, d_second = dijkstra.find_second_shortest(source, target)
        d_time = time.perf_counter() - start_time
        d_stats = dijkstra.get_statistics()
        
        # æµ‹è¯• State-Extended SPFA
        spfa = StateExtendedSPFA(graph)
        start_time = time.perf_counter()
        s_shortest, s_second = spfa.find_second_shortest(source, target)
        s_time = time.perf_counter() - start_time
        s_stats = spfa.get_statistics()
        
        # éªŒè¯ç»“æœï¼ˆå¦‚æœæœ‰é¢„æœŸï¼‰
        dijkstra_correct = None
        spfa_correct = None
        
        if has_expected:
            dijkstra_correct = (d_shortest == expected_shortest and 
                               d_second == expected_second)
            spfa_correct = (s_shortest == expected_shortest and 
                           s_second == expected_second)
            
            d_status = "âœ…" if dijkstra_correct else "âŒ"
            s_status = "âœ…" if spfa_correct else "âŒ"
            
            logger.info(f"  Dijkstra: {d_status} æœ€çŸ­={d_shortest}, æ¬¡çŸ­={d_second} "
                       f"(è€—æ—¶: {d_time*1000:.2f}ms)")
            logger.info(f"  SPFA:     {s_status} æœ€çŸ­={s_shortest}, æ¬¡çŸ­={s_second} "
                       f"(è€—æ—¶: {s_time*1000:.2f}ms)")
            
            official_cases.append({
                'case_id': case_id,
                'name': name,
                'dijkstra_correct': dijkstra_correct,
                'spfa_correct': spfa_correct,
            })
        else:
            logger.info(f"  Dijkstra: æœ€çŸ­={d_shortest}, æ¬¡çŸ­={d_second} "
                       f"(è€—æ—¶: {d_time*1000:.2f}ms)")
            logger.info(f"  SPFA:     æœ€çŸ­={s_shortest}, æ¬¡çŸ­={s_second} "
                       f"(è€—æ—¶: {s_time*1000:.2f}ms)")
            
            generated_cases.append({
                'case_id': case_id,
                'name': name,
            })
        
        # è®°å½•ç»“æœ
        results.append({
            'case_id': case_id,
            'name': name,
            'n': n,
            'm': len(edges),
            'has_expected': has_expected,
            'dijkstra_time': d_time,
            'dijkstra_shortest': d_shortest,
            'dijkstra_second': d_second,
            'dijkstra_correct': dijkstra_correct,
            'dijkstra_pq_ops': d_stats.get('pq_operations', 0),
            'dijkstra_edge_relax': d_stats.get('edge_relaxations', 0),
            'spfa_time': s_time,
            'spfa_shortest': s_shortest,
            'spfa_second': s_second,
            'spfa_correct': spfa_correct,
            'spfa_queue_ops': s_stats.get('enqueue_operations', 0),
            'spfa_edge_relax': s_stats.get('edge_relaxations', 0),
        })
        
        logger.info("")
    
    # ç”Ÿæˆæ€»ç»“
    logger.info("=" * 70)
    logger.info("å®éªŒæ€»ç»“")
    logger.info("=" * 70)
    
    df = pd.DataFrame(results)
    
    # è½¬æ¢ä¸ºé•¿æ ¼å¼ï¼ˆé•¿è¡¨æ ¼å¼ï¼‰ä»¥å…¼å®¹å¯è§†åŒ–å‡½æ•°
    # åˆ›å»ºä¸¤ä¸ªç®—æ³•çš„ç»“æœåˆ—è¡¨
    viz_results = []
    
    for _, row in df.iterrows():
        # Dijkstra ç»“æœ
        viz_results.append({
            'case_id': row['case_id'],
            'name': row['name'],
            'n': row['n'],
            'm': row['m'],
            'algorithm': 'Dijkstra',
            'time': row['dijkstra_time'],
            'shortest': row['dijkstra_shortest'],
            'second': row['dijkstra_second'],
            'correct': row['dijkstra_correct'],
            'operations': row['dijkstra_pq_ops'],
        })
        
        # SPFA ç»“æœ
        viz_results.append({
            'case_id': row['case_id'],
            'name': row['name'],
            'n': row['n'],
            'm': row['m'],
            'algorithm': 'SPFA',
            'time': row['spfa_time'],
            'shortest': row['spfa_shortest'],
            'second': row['spfa_second'],
            'correct': row['spfa_correct'],
            'operations': row['spfa_queue_ops'],
        })
    
    viz_df = pd.DataFrame(viz_results)
    
    # å®˜æ–¹ç”¨ä¾‹ç»Ÿè®¡
    official_correct = [r for r in results if r['has_expected'] and r['dijkstra_correct']]
    official_total = len([r for r in results if r['has_expected']])
    
    logger.info(f"\nğŸ“Š å®˜æ–¹æµ‹è¯•ç”¨ä¾‹:")
    logger.info(f"  æ€»æ•°: {official_total}")
    logger.info(f"  Dijkstra é€šè¿‡: {sum(1 for r in results if r['has_expected'] and r['dijkstra_correct'])}/{official_total}")
    logger.info(f"  SPFA é€šè¿‡: {sum(1 for r in results if r['has_expected'] and r['spfa_correct'])}/{official_total}")
    
    if official_total > 0:
        logger.info(f"  Dijkstra æ­£ç¡®ç‡: {sum(1 for r in results if r['has_expected'] and r['dijkstra_correct'])/official_total*100:.1f}%")
        logger.info(f"  SPFA æ­£ç¡®ç‡: {sum(1 for r in results if r['has_expected'] and r['spfa_correct'])/official_total*100:.1f}%")
    
    # æ€§èƒ½ç»Ÿè®¡
    logger.info(f"\nâš¡ æ€§èƒ½å¯¹æ¯”:")
    dijkstra_avg_time = df['dijkstra_time'].mean()
    spfa_avg_time = df['spfa_time'].mean()
    
    logger.info(f"  Dijkstra å¹³å‡è€—æ—¶: {dijkstra_avg_time*1000:.2f}ms")
    logger.info(f"  SPFA å¹³å‡è€—æ—¶: {spfa_avg_time*1000:.2f}ms")
    
    if dijkstra_avg_time > 0 and spfa_avg_time > 0:
        speedup = dijkstra_avg_time / spfa_avg_time
        faster = "Dijkstra" if speedup > 1 else "SPFA"
        logger.info(f"  {faster} å¿« {abs(speedup - 1)*100:.1f}%")
    
    # æ“ä½œç»Ÿè®¡
    dijkstra_avg_ops = df['dijkstra_pq_ops'].mean()
    spfa_avg_ops = df['spfa_queue_ops'].mean()
    
    logger.info(f"\nğŸ“ˆ æ“ä½œç»Ÿè®¡:")
    logger.info(f"  Dijkstra å¹³å‡PQæ“ä½œæ•°: {dijkstra_avg_ops:.0f}")
    logger.info(f"  SPFA å¹³å‡é˜Ÿåˆ—æ“ä½œæ•°: {spfa_avg_ops:.0f}")
    
    logger.info("=" * 70)
    
    # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
    logger.info("\nğŸ’¾ ä¿å­˜æŠ¥å‘Š...\n")
    
    # JSON æŠ¥å‘Š
    report = {
        'metadata': {
            'total_cases': total_cases,
            'official_cases': official_total,
            'generated_cases': len(generated_cases),
        },
        'summary': {
            'dijkstra': {
                'avg_time': float(dijkstra_avg_time),
                'correct_count': sum(1 for r in results if r['has_expected'] and r['dijkstra_correct']),
                'total': official_total,
                'accuracy': sum(1 for r in results if r['has_expected'] and r['dijkstra_correct']) / official_total if official_total > 0 else 0,
                'avg_pq_ops': float(dijkstra_avg_ops),
                'avg_edge_relax': float(df['dijkstra_edge_relax'].mean()),
            },
            'spfa': {
                'avg_time': float(spfa_avg_time),
                'correct_count': sum(1 for r in results if r['has_expected'] and r['spfa_correct']),
                'total': official_total,
                'accuracy': sum(1 for r in results if r['has_expected'] and r['spfa_correct']) / official_total if official_total > 0 else 0,
                'avg_queue_ops': float(spfa_avg_ops),
                'avg_edge_relax': float(df['spfa_edge_relax'].mean()),
            },
        },
        'details': results,
    }
    
    report_path = metrics_dir / "leetcode_report.json"
    with open(report_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    logger.info(f"âœ… JSON æŠ¥å‘Š: {report_path}")
    
    # CSV æŠ¥å‘Š
    csv_path = metrics_dir / "leetcode_results.csv"
    df.to_csv(csv_path, index=False)
    logger.info(f"âœ… CSV æŠ¥å‘Š: {csv_path}")
    
    # ç”Ÿæˆå¯è§†åŒ–
    logger.info("\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...\n")
    
    try:
        Visualizer.plot_runtime_comparison(viz_df, viz_dir / "runtime_comparison.png")
        logger.info("âœ… è¿è¡Œæ—¶é—´å¯¹æ¯”å›¾")
    except Exception as e:
        logger.warning(f"âš ï¸  è¿è¡Œæ—¶é—´å¯¹æ¯”å›¾ç”Ÿæˆå¤±è´¥: {e}")
    
    try:
        Visualizer.plot_scalability(viz_df, viz_dir / "scalability.png")
        logger.info("âœ… å¯æ‰©å±•æ€§åˆ†æå›¾")
    except Exception as e:
        logger.warning(f"âš ï¸  å¯æ‰©å±•æ€§åˆ†æå›¾ç”Ÿæˆå¤±è´¥: {e}")
    
    try:
        Visualizer.plot_percentile_comparison(viz_df, viz_dir / "percentile_comparison.png")
        logger.info("âœ… ç™¾åˆ†ä½æ•°å¯¹æ¯”å›¾")
    except Exception as e:
        logger.warning(f"âš ï¸  ç™¾åˆ†ä½æ•°å¯¹æ¯”å›¾ç”Ÿæˆå¤±è´¥: {e}")
    
    logger.info("\n" + "=" * 70)
    logger.info("âœ… å®éªŒå®Œæˆï¼")
    logger.info(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {output_path}")
    logger.info("=" * 70)


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='åœ¨LeetCodeæ•°æ®ä¸Šè¿è¡Œç®—æ³•å®éªŒ'
    )
    parser.add_argument(
        '--data',
        type=str,
        default='data/leetcode/leetcode_second_shortest_path.json',
        help='LeetCodeæ•°æ®æ–‡ä»¶è·¯å¾„'
    )
    parser.add_argument(
        '--output',
        type=str,
        default='results/leetcode_experiments',
        help='è¾“å‡ºç›®å½•'
    )
    
    args = parser.parse_args()
    
    data_path = Path(args.data)
    if not data_path.exists():
        logger.error(f"âŒ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {data_path}")
        sys.exit(1)
    
    try:
        run_leetcode_experiments(str(data_path), args.output)
    except Exception as e:
        logger.error(f"âŒ å®éªŒè¿è¡Œå¤±è´¥: {e}", exc_info=True)
        sys.exit(1)


if __name__ == "__main__":
    main()
